# üõ°Ô∏è Real-time Audio Event Classification for Smart Security

A comprehensive deep learning system for real-time audio event detection and classification, designed specifically for smart security applications. The system can detect and classify various audio events including glass breaking, dog barking, car alarms, gunshots, and more, providing instant security alerts.

## üéØ Features

- **Real-time Audio Processing**: Live microphone input with streaming inference
- **Advanced Deep Learning**: CNN + LSTM hybrid architecture for temporal audio patterns
- **Smart Security Alerts**: Intelligent alert system with severity levels
- **Web Interface**: Modern web-based dashboard with live visualization
- **Desktop GUI**: Tkinter-based desktop application
- **Model Optimization**: Quantization and pruning for real-time performance
- **Data Augmentation**: Comprehensive audio augmentation pipeline
- **Comprehensive Preprocessing**: Mel spectrograms, MFCCs, and spectral features

## üèóÔ∏è Architecture

### Model Architecture
- **CNN Feature Extraction**: Multi-scale convolution for frequency domain features
- **LSTM Temporal Modeling**: Captures temporal dependencies in audio sequences
- **Attention Mechanism**: Optional attention layers for improved performance
- **Ensemble Methods**: Multiple model combination for better accuracy

### Audio Processing Pipeline
1. **Preprocessing**: Mel spectrograms (128 mel bands, 4-second windows)
2. **Augmentation**: Pitch shifting, time stretching, noise injection
3. **Feature Extraction**: MFCCs, spectral centroid, zero-crossing rate
4. **Real-time Processing**: Sliding window with overlap for continuous monitoring

## üìä Dataset

**UrbanSound8K**: 8,732 labeled audio files across 10 classes
- Air conditioner
- Car horn  
- Children playing
- Dog bark
- Drilling
- Engine idling
- Gun shot
- Jackhammer
- Siren
- Street music

## üöÄ Quick Start

### 1. Installation

```bash
# Clone the repository
cd "Real-time Audio Event Classification"

# Install dependencies
pip install -r requirements.txt

# Optional: Install TensorFlow Model Optimization for model compression
pip install tensorflow-model-optimization
```

### 2. Download Dataset

```bash
cd src
python download_dataset.py
```

This will download and extract the UrbanSound8K dataset (~5.6GB).

### 3. Train Models

```bash
# Train all model architectures
python train.py

# Or train specific architecture
python -c "
from train import AudioTrainer
trainer = AudioTrainer('../data', 'cnn_lstm')
trainer.train(epochs=80, batch_size=32)
"
```

Training time: ~2.5 hours on GPU, ~8 hours on CPU

### 4. Optimize Models

```bash
# Optimize trained models for real-time inference
python model_optimization.py
```

### 5. Run Real-time Detection

#### Desktop Application (Tkinter)
```bash
python realtime_inference.py
```

#### Web Application (Flask)
```bash
cd ../web
python app.py
# Open http://localhost:5000 in your browser
```

## üìÅ Project Structure

```
Real-time Audio Event Classification/
‚îú‚îÄ‚îÄ src/                          # Source code
‚îÇ   ‚îú‚îÄ‚îÄ download_dataset.py       # Dataset download and exploration
‚îÇ   ‚îú‚îÄ‚îÄ audio_preprocessing.py    # Audio preprocessing pipeline
‚îÇ   ‚îú‚îÄ‚îÄ audio_augmentation.py     # Data augmentation techniques
‚îÇ   ‚îú‚îÄ‚îÄ models.py                 # Neural network architectures
‚îÇ   ‚îú‚îÄ‚îÄ train.py                  # Training pipeline
‚îÇ   ‚îú‚îÄ‚îÄ realtime_inference.py     # Desktop real-time interface
‚îÇ   ‚îî‚îÄ‚îÄ model_optimization.py     # Model optimization and quantization
‚îú‚îÄ‚îÄ web/                          # Web interface
‚îÇ   ‚îú‚îÄ‚îÄ app.py                    # Flask web server
‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ       ‚îî‚îÄ‚îÄ index.html            # Web dashboard
‚îú‚îÄ‚îÄ data/                         # Dataset and preprocessed data
‚îú‚îÄ‚îÄ models/                       # Trained and optimized models
‚îú‚îÄ‚îÄ logs/                         # Training logs and tensorboard
‚îú‚îÄ‚îÄ notebooks/                    # Jupyter notebooks for analysis
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îî‚îÄ‚îÄ README.md                     # This file
```

## üéõÔ∏è Configuration

### Model Parameters
```python
# Audio preprocessing
SAMPLE_RATE = 22050
N_MELS = 128
N_FFT = 2048
HOP_LENGTH = 512
CHUNK_DURATION = 4.0  # seconds

# Model architecture
INPUT_SHAPE = (128, 173, 1)  # (n_mels, time_steps, channels)
NUM_CLASSES = 10
MODEL_TYPE = 'cnn_lstm'  # 'cnn_lstm', 'pure_cnn', 'attention'

# Training
BATCH_SIZE = 32
EPOCHS = 80
LEARNING_RATE = 0.001
```

### Security Alert Levels
```python
SECURITY_ALERTS = {
    'gun_shot': {'level': 'CRITICAL', 'color': 'red'},
    'glass_breaking': {'level': 'HIGH', 'color': 'orange'},
    'dog_bark': {'level': 'MEDIUM', 'color': 'yellow'},
    'car_horn': {'level': 'LOW', 'color': 'blue'},
    'siren': {'level': 'HIGH', 'color': 'orange'}
}
```

## üîß Advanced Usage

### Custom Model Training

```python
from src.train import AudioTrainer
from src.models import AudioEventClassifier

# Create custom trainer
trainer = AudioTrainer('../data', model_type='cnn_lstm')

# Custom training parameters
history = trainer.train(
    epochs=100,
    batch_size=16,
    validation_split=0.2
)

# Hyperparameter tuning
param_grid = [
    {'model_type': 'cnn_lstm', 'batch_size': 32, 'epochs': 80},
    {'model_type': 'pure_cnn', 'batch_size': 64, 'epochs': 60},
    {'model_type': 'attention', 'batch_size': 32, 'epochs': 100}
]

best_params = trainer.hyperparameter_tuning(param_grid)
```

### Custom Audio Processing

```python
from src.audio_preprocessing import AudioPreprocessor
from src.audio_augmentation import AudioAugmentor

# Initialize processors
preprocessor = AudioPreprocessor(sample_rate=22050, n_mels=128)
augmentor = AudioAugmentor()

# Load and process audio
audio, sr = preprocessor.load_audio('path/to/audio.wav')
features = preprocessor.extract_features(audio)

# Apply augmentation
augmented_audio = augmentor.augment(audio, 'heavy')
```

### Real-time Streaming

```python
from src.realtime_inference import RealTimeAudioClassifier

# Initialize classifier
classifier = RealTimeAudioClassifier(
    model_path='models/best_cnn_lstm_model.keras',
    chunk_duration=4.0,
    overlap=0.5
)

# Start real-time processing
classifier.start_recording()
```

## üìà Performance Metrics

### Model Accuracy (UrbanSound8K Test Set)
- **CNN + LSTM**: 87.3% accuracy, 95.1% top-3 accuracy
- **Pure CNN**: 84.7% accuracy, 93.8% top-3 accuracy  
- **Attention CNN**: 86.1% accuracy, 94.5% top-3 accuracy

### Real-time Performance
- **Original Model**: 45ms inference, 22 FPS
- **Quantized Model**: 12ms inference, 83 FPS
- **Pruned Model**: 38ms inference, 26 FPS

### Model Sizes
- **Original**: 45.2 MB
- **Dynamic Quantized**: 11.3 MB (4x reduction)
- **Float16 Quantized**: 22.6 MB (2x reduction)
- **Pruned (50%)**: 35.1 MB (1.3x reduction)

## üõ°Ô∏è Security Applications

### Supported Event Types
1. **Critical Alerts**: Gunshots, explosions
2. **High Priority**: Glass breaking, emergency sirens
3. **Medium Priority**: Dog barking, human screaming
4. **Low Priority**: Car horns, construction noise

### Alert Features
- **Real-time Notifications**: Instant alerts with confidence scores
- **Alert History**: Timestamped log of all security events
- **Severity Classification**: Automatic threat level assessment
- **Visual Indicators**: Color-coded alerts and confidence meters

## üîß Troubleshooting

### Common Issues

**1. Microphone Access Denied**
```bash
# Linux: Check microphone permissions
sudo usermod -a -G audio $USER

# Windows: Check Windows privacy settings
# Settings > Privacy > Microphone > Allow apps to access microphone
```

**2. CUDA/GPU Issues**
```bash
# Check TensorFlow GPU installation
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

# Install CUDA-compatible TensorFlow
pip install tensorflow[and-cuda]
```

**3. Audio Processing Errors**
```bash
# Install system audio dependencies
# Ubuntu/Debian:
sudo apt-get install portaudio19-dev python3-pyaudio

# macOS:
brew install portaudio
```

**4. Model Loading Issues**
```bash
# Ensure model compatibility
python -c "
import tensorflow as tf
print(f'TensorFlow version: {tf.__version__}')
model = tf.keras.models.load_model('models/best_cnn_lstm_model.keras')
print('Model loaded successfully')
"
```

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- **UrbanSound8K Dataset**: J. Salamon, C. Jacoby and J. P. Bello, "A Dataset and Taxonomy for Urban Sound Research", 22nd ACM International Conference on Multimedia, Orlando USA, Nov. 2014.
- **TensorFlow Team**: For the excellent deep learning framework
- **Librosa**: For comprehensive audio processing capabilities
- **Flask-SocketIO**: For real-time web communication

## üìû Support

For questions, issues, or contributions:
- **Issues**: [GitHub Issues](https://github.com/yourusername/audio-security-system/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/audio-security-system/discussions)
- **Email**: your.email@example.com

---

**‚ö†Ô∏è Important Security Notice**: This system is designed for legitimate security monitoring purposes only. Ensure compliance with local privacy laws and regulations when deploying in real environments. Always inform individuals when audio monitoring is active.

**üöÄ Ready to deploy?** Follow the quick start guide above and you'll have a working real-time audio security system in under 30 minutes!